{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches as ptc \n",
    "import math\n",
    "import random\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0041d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train0, y_train0), (x_test0, y_test0) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = np.asarray(x_train0, dtype=np.float32).reshape(60000, 28*28) / 255.0\n",
    "x_test = np.asarray(x_test0, dtype=np.float32).reshape(10000, 28*28) / 255.0\n",
    "y_train = np.asarray(y_train0, dtype=np.int32)\n",
    "y_test = np.asarray(y_test0, dtype=np.int32)\n",
    "\n",
    "y_train_onehot =  tf.one_hot( y_train, depth=10, dtype=tf.float32)\n",
    "y_test_onehot =  tf.one_hot( y_test, depth=10, dtype=tf.float32)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f8c58-17cd-4606-b500-0e08d028aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_img = 5\n",
    "plt.imshow(x_train0[num_img], cmap='gray')\n",
    "plt.title(f\"Label: {y_train0[num_img]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train_onehot.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc7f55d-6968-4be3-bcea-2cd04be93d5f",
   "metadata": {},
   "source": [
    "# Why we use TensorFlow?\n",
    "* Our code will run on GPUs (Not today's tutorial)! Much faster training. \n",
    "* We want you to be ready to use the framework for your project so you can experiment more efficiently than with the code we wrote by hand. \n",
    "* We want you to stand on the shoulders of giants! TensorFlow and PyTorch are both excellent frameworks that will make your lives a lot easier :)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f8c34-39e1-47f3-8bff-29927bc31c30",
   "metadata": {},
   "source": [
    "# Keras Sequential API\n",
    "In Keras, there's easy way to define the neural network which is expressed as a sequential stack of layers, with the outpupt of each layer fed to the next layer as input. Simply call the `tf.keras.Sequential` constructor with a list containing a sequence of layer objects.\n",
    "\n",
    "\n",
    "To define each layers, we will pick one type of layer from `tf.keras.layers`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0675a6c-9ac8-4eaf-99a3-4423e3702697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_net():\n",
    "    model = tf.keras.Sequential(layers = [\n",
    "        tf.keras.layers.InputLayer(input_shape=(28,28,1),name = 'input'),\n",
    "        tf.keras.layers.Conv2D(5, 3,activation= 'relu',name = 'conv'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation='softmax',name = 'output')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b45aad-915c-44b6-b883-467444d41cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = two_layer_net()\n",
    "model.summary()\n",
    "#tf.keras.utils.plot_model(model, \"model.png\")\n",
    "#plot_model(model, to_file = 'neuralnet_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0d17a-b78f-454f-a519-b8754620041d",
   "metadata": {},
   "source": [
    "To train the network, we defined the loss function (ex.MSE or CrossEntropy) and minimize the loss function using the Stochastic Gradient Decent, which requires to compute the gradient of loss function with respect to each weights and bias. The way of computing each gradient is called back-progagation.  In Keras seqeuntial API, `.complie()` deals with every jobs above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_net():\n",
    "    model = tf.keras.Sequential(layers = [\n",
    "        tf.keras.layers.InputLayer(input_shape=(28,28,1),name = 'input'),\n",
    "        tf.keras.layers.Conv2D(5, 3, activation= 'relu',name = 'conv'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation='softmax',name = 'output')\n",
    "              \n",
    "\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dcd5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5866f-9c0e-4a26-bbb9-23b12d2a11b9",
   "metadata": {},
   "source": [
    "Once we decide the complier, we need to train the model by fitting on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c5912",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = two_layer_net()\n",
    "training_history = model.fit(x_train0.reshape(60000,28,28,1), y_train_onehot, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99209536",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = training_history.history['loss']\n",
    "Accuracy = training_history.history['accuracy']\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(Loss, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "              \n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(Accuracy, label='Training Accuracy', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy over Epochs')\n",
    "\n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf685ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test.reshape(10000,28,28,1), y_test_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8035187",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train0[5], cmap='gray')\n",
    "pred = model.predict(x_train[5:6].reshape(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81835661",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596848bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in enumerate(x_test0[0:64]):\n",
    "    plt.subplot(8, 8, i+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    #prediction = model.predict(x_test[i:i+1])\n",
    "    #pred_label = np.argmax(prediction)\n",
    "    \n",
    "    #plt.title(f' {pred_label,np.round(prediction[0,pred_label],decimals=3)}')\n",
    "    plt.tight_layout()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = model.layers[0].get_weights()[0]\n",
    "np.shape(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cbd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.abs(filters).max()\n",
    "plt.imshow(filters[:,:,:,0].reshape(3,3), cmap='gray', vmin=-m, vmax=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b2f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 10\n",
    "rows = 10\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20,20))\n",
    "idxs = range(rows*cols)\n",
    "m = np.abs(weights).max()\n",
    "for ax, j in zip(axes.ravel(), idxs):\n",
    "    ax.imshow(weights[:, j].reshape(28,28), cmap='gray', vmin=-m, vmax=m)\n",
    "    ax.set_title(str(j), fontsize=8)\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"hidden1 weights\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b810dc2d-3a14-49c9-9b79-9a8627d38050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92c8bfc8-e695-4744-adb0-49f3ad50f797",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a3ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convolution(input, filter):\n",
    "    r_filter, c_filter = filter.shape\n",
    "    row = input.shape[0] - r_filter + 1\n",
    "    col = input.shape[1] - c_filter + 1\n",
    "   \n",
    "    output = np.zeros((row, col))\n",
    "\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            part = input[i:i+r_filter,j:j+c_filter]\n",
    "            output[i,j] = (filter* part).sum()\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba06a75-59da-4dca-89ad-1d878ce4ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image = np.array([[0, 0, 1, 0],[0, 1,0.5,0], [1,0,1,0],[1,0.5,1,1]])\n",
    "Filter = np.array([[1,0,-1],[1,0,-1],[1,0,-1]])\n",
    "Output = convolution(Image, Filter)\n",
    "Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fb1087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_img0 =1\n",
    "input0 = x_train0[num_img0]\n",
    "plt.imshow(input, cmap='gray')\n",
    "\n",
    "plt.title('size of image is %d x %d '%(input0.shape[0], input0.shape[1]),fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134300e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = convolution(input0, Filter)\n",
    "plt.imshow(output, cmap='gray')\n",
    "#plt.title('what is the size of output?',fontsize = 20)\n",
    "plt.title('Size of image is %d x %d '%(output.shape[0], output.shape[1]),fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a986e74-0017-4779-9394-60e3ff059863",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [np.array([[0,0,0],[0,1,0],[0,0,0]]),np.array([[1,0,-1],[1,0,-1],[1,0,-1]]), np.array([[1,1,1],[0,0,0],[-1,-1,-1]]), np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]]),np.array([[1,1,1],[1,1,1],[1,1,1]])] #np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])]  \n",
    "name_filters = ['identity', 'vertical edge detector', 'horizontal edge detector', 'edge detector', 'blur']\n",
    "cols = 4\n",
    "rows = 5\n",
    "\n",
    "num_img1 =6\n",
    "input1 = x_train0[num_img1]\n",
    "\n",
    "num_img5 =239\n",
    "input5 = x_train0[num_img5]\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 20))\n",
    "\n",
    "for i in range(rows):\n",
    "    filter = filters[i] \n",
    "    axes[ i,0].imshow(filters[i], cmap='gray')\n",
    "    axes[ i,0].set_title(name_filters[i])\n",
    "    axes[ i,0].axis('off')\n",
    "\n",
    "    \n",
    "    for x in range(filter.shape[1] + 1):\n",
    "        axes[i,0].axvline(x - 0.5, color='yellow', linewidth=1)\n",
    "    for y in range(filter.shape[0] + 1):\n",
    "        axes[i,0].axhline(y - 0.5, color='yellow', linewidth=1)\n",
    "        \n",
    "    \n",
    "    for y in range(filter.shape[0]):\n",
    "        for x in range(filter.shape[1]):\n",
    "            axes[i,0].text(x, y, f\"{filter[y, x]:.0f}\",\n",
    "                    ha='center', va='center', color='blue',\n",
    "                    fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Right: output\n",
    "    axes[i,1].imshow(convolution(input0,filter), cmap='gray')\n",
    "    axes[i,1].axis('off')\n",
    "    axes[i,2].imshow(convolution(input1,filter), cmap='gray')\n",
    "    axes[i,2].axis('off')\n",
    "    axes[i,3].imshow(convolution(input5,filter), cmap='gray')\n",
    "   \n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a3fffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [np.array([[0,0,0],[0,1,0],[0,0,0]]),np.array([[1,0,-1],[1,0,-1],[1,0,-1]]), np.array([[1,1,1],[0,0,0],[-1,-1,-1]]), np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]]),np.array([[1,1,1],[1,1,1],[1,1,1]])] #np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])]  \n",
    "name_filters = ['identity', 'vertical edge detector', 'horizontal edge detector', 'edge detector', 'blur']\n",
    "cols = 5\n",
    "rows = 2\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 10))\n",
    "\n",
    "for i in range(cols):\n",
    "    filter = filters[i] \n",
    "    axes[ 0,i].imshow(filters[i], cmap='gray')\n",
    "    axes[ 0,i].set_title(name_filters[i])\n",
    "    axes[ 0,i].axis('off')\n",
    "\n",
    "    \n",
    "    for x in range(filter.shape[1] + 1):\n",
    "        axes[0,i].axvline(x - 0.5, color='yellow', linewidth=1)\n",
    "    for y in range(filter.shape[0] + 1):\n",
    "        axes[0,i].axhline(y - 0.5, color='yellow', linewidth=1)\n",
    "        \n",
    "    \n",
    "    for y in range(filter.shape[0]):\n",
    "        for x in range(filter.shape[1]):\n",
    "            axes[0,i].text(x, y, f\"{filter[y, x]:.0f}\",\n",
    "                    ha='center', va='center', color='blue',\n",
    "                    fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Right: output\n",
    "    axes[1,i].imshow(convolution(input,filter), cmap='gray')\n",
    "    axes[1,i].axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d59d75-a7df-4ce4-b1fa-29bbde94d015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee1bdf-feb7-4816-b00a-f9d09625b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y_train == 1)[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a5655-2977-46e6-93bf-06057f517dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a43b2-9787-4e99-ae0b-a02fbd7c35fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_img0 =239\n",
    "input0 = x_train0[num_img0]\n",
    "plt.imshow(input0, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf739935-40d4-49db-9e8c-167676b23ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y_train == 5)[0][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e29d8c-0838-4d4a-999c-f9534a7b778e",
   "metadata": {},
   "source": [
    "# Tensorflow for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d940887-ae5b-4b89-bbdb-0a317a55ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train0, y_train0), (x_test0, y_test0) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train0.reshape(60000, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test = x_test0.reshape(10000, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "y_train = np.asarray(y_train0, dtype=np.int32)\n",
    "y_test = np.asarray(y_test0, dtype=np.int32)\n",
    "\n",
    "y_train_onehot =  tf.one_hot( y_train, depth=10, dtype=tf.float32)\n",
    "y_test_onehot =  tf.one_hot( y_test, depth=10, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb3124-1b5b-4964-a0c6-3d1c2559be6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d371f3d8-1968-49ef-aee9-53c0f0a68c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_cov():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(shape=(28, 28, 1), name='input'),\n",
    "        tf.keras.layers.Conv2D(5, 7, activation='relu', strides = 2, name='conv1'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd153bb1-bb2d-4c7d-b76c-3f5c0c8cbe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = two_layer_cov()\n",
    "plot_model(model2, to_file = 'neuralnet_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ff121b-5197-4354-a5a0-3af6293d92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = two_layer_cov()\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "training_history2 = model2.fit(x_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b304f374-6e79-466c-9556-fb4b2a39fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model2.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554fbdf-490b-4550-a3a4-52a0b0d012db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = training_history2.history['loss']\n",
    "Accuracy = training_history2.history['accuracy']\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(Loss, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "              \n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(Accuracy, label='Training Accuracy', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy over Epochs')\n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c5ba3a-fc67-4c49-a055-0d076a8db585",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = model2.layers[0].get_weights()[0]\n",
    "\n",
    "#[0].get_weights()[0]\n",
    "#np.shape(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d9dc50-4aa0-44fe-b927-8181dfa84c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 5\n",
    "rows = 1\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20,4))\n",
    "idxs = range(rows*cols)\n",
    "m = np.abs(filters).max()\n",
    "for ax, j in zip(axes.ravel(), idxs):\n",
    "    ax.imshow(filters[:,:,:, j].reshape(7,7), cmap='gray', vmin=-m, vmax=m)\n",
    "    ax.set_title(str(j), fontsize=8)\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"hidden1 weights\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f6bce-925f-4ce1-954d-5793dbf52b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0656797-addd-4970-b93f-cb07bfb4826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_layer_cov():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(shape=(28, 28, 1), name='input'),\n",
    "        tf.keras.layers.Conv2D(5, 7, activation='relu', name='conv1'),\n",
    "        tf.keras.layers.Conv2D(10, 3, activation='relu', name='conv2'), \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8aa090-f3ab-4a9c-ac82-46643c27fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = three_layer_cov()\n",
    "plot_model(model3, to_file = 'neuralnet_model.png', show_shapes=True, show_layer_names=True)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a2950-50d7-4436-aa0f-da2296da6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_layer_pooling_cov():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(shape=(28, 28, 1), name='input'),\n",
    "        tf.keras.layers.Conv2D(5, 7, activation='relu', name='conv1'),\n",
    "        tf.keras.layers.MaxPooling2D(2, name='pool1'),\n",
    "        tf.keras.layers.Conv2D(10, 3, activation='relu', name='conv2'),\n",
    "        tf.keras.layers.MaxPooling2D(2, name='pool2'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438af1d0-0553-4993-b83d-2f7c99cc6673",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = three_layer_pooling_cov()\n",
    "plot_model(model4, to_file = 'neuralnet_model.png', show_shapes=True, show_layer_names=True)\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec574f-266a-46bf-9a9b-ba9ea904de2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7fc88-977a-4c09-9d8a-d8f5f55ebae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4= three_layer_pooling_cov()\n",
    "model4.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "training_history4 = model4.fit(x_train, y_train, epochs=5)\n",
    "test_loss, test_acc = model4.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df63cc1-4e8b-4523-b738-01e046358350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10ffec-39c9-4315-8a2e-b66baec73693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bfb164-c7ae-4231-bfcb-6b418722fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train0, y_train0), (x_test0, y_test0) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train0.reshape(50000, 32, 32, 3).astype(\"float32\") / 255.0\n",
    "x_test = x_test0.reshape(10000, 32, 32, 3).astype(\"float32\") / 255.0\n",
    "y_train = np.asarray(y_train0, dtype=np.int32)\n",
    "y_test = np.asarray(y_test0, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in enumerate(x_test0[0:64]):\n",
    "    plt.subplot(8, 8, i+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    #prediction = model.predict(x_test[i:i+1])\n",
    "    #pred_label = np.argmax(prediction)\n",
    "    \n",
    "   \n",
    "    plt.tight_layout()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e034af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NerualNet_3_channel():\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(shape=(32, 32, 3), name='input'),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu', name='conv1'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.MaxPooling2D(2, name='pool1'),\n",
    "        tf.keras.layers.Conv2D(10, 3, activation='relu', name='conv2'),\n",
    "        tf.keras.layers.MaxPooling2D(2, name='pool2'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
    "       \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = NerualNet_3_channel()\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be68593",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = NerualNet_3_channel()\n",
    "model5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "training_history5 = model5.fit(x_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d15a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
